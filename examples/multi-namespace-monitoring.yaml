# Multi-Namespace Monitoring Example
# This example shows how to set up monitoring across multiple namespaces
# with different agents for different environments.

apiVersion: kagent.dev/v1alpha2
kind: Hook
metadata:
  name: staging-monitoring
  namespace: staging
  labels:
    environment: staging
    monitoring-type: pre-production
spec:
  eventConfigurations:
  # Staging environment monitoring with production-like analysis
  - eventType: pod-restart
    agentId: staging-analyzer
    prompt: |
      AUTONOMOUS MODE: STAGING - Pod {{.ResourceName}} restarted at {{.EventTime}}. Analyze and fix immediately.

      INSTRUCTIONS:
      • Use all available tools to diagnose and resolve the issue
      • Compare with production behavior and validate deployment changes
      • Annotate fixed resources with: kagentFix=<timestamp>
      • If patching fails: delete and recreate resources
      • Never ask for permission - assume autonomous execution
      • Complete remediation without human approval

  - eventType: probe-failed
    agentId: staging-analyzer
    prompt: |
      AUTONOMOUS MODE: STAGING - Health probe failed for {{.ResourceName}} at {{.EventTime}}. Fix immediately.

      INSTRUCTIONS:
      • Use all available tools to diagnose and resolve health check issues
      • Validate probe configurations and timeouts for production readiness
      • Annotate fixed resources with: kagentFix=<timestamp>
      • If patching fails: delete and recreate resources
      • Never ask for permission - assume autonomous execution
      • Complete remediation without human approval

---
apiVersion: kagent.dev/v1alpha2
kind: Hook
metadata:
  name: test-monitoring
  namespace: test
  labels:
    environment: test
    monitoring-type: automated-testing
spec:
  eventConfigurations:
  # Test environment with focus on CI/CD pipeline issues
  - eventType: pod-pending
    agentId: ci-cd-helper
    prompt: |
      AUTONOMOUS MODE: TEST ENV - Pod {{.ResourceName}} pending since {{.EventTime}}. Resolve scheduling issue immediately.

      INSTRUCTIONS:
      • Use all available tools to diagnose scheduling constraints
      • Check test cluster resources, data setup, and configuration conflicts
      • Annotate fixed resources with: kagentFix=<timestamp>
      • If patching fails: delete and recreate resources
      • Never ask for permission - assume autonomous execution
      • Complete remediation without human approval